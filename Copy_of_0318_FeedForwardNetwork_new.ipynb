{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 0318_FeedForwardNetwork_new.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "rLpsoFqkPWCA",
        "Y3UpXEpCZg5S"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bekbote/project_repository/blob/master/Copy_of_0318_FeedForwardNetwork_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zzM664z9NnfC"
      },
      "source": [
        "**Outline**\n",
        "1. Generate data that is not linearly separable\n",
        "2. Train with SN and see performance\n",
        "3. Write from scratch our first feed forward network\n",
        "4. Train the FF network on the data and compare with SN\n",
        "5. Write a generic class for a FF network\n",
        "6. Train generic class on binary classification\n",
        "7. Generate data for multi-class classification\n",
        "8. Train a FF network for 7\n",
        "9. Use softmax as the output layer and cross-entropy loss function\n",
        "10. Train with 8 for multi-class classification\n",
        "11. Exercises on other datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MMkrXXWZQ42d"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JDe7l4fxQ6J9",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "from tqdm import tqdm_notebook \n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.datasets import make_blobs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Dk5nd5ccQ8dd",
        "colab": {}
      },
      "source": [
        "class SigmoidNeuron:\n",
        "    \n",
        "  def __init__(self):\n",
        "    self.w = None\n",
        "    self.b = None\n",
        "    \n",
        "  def perceptron(self, x):\n",
        "    return np.dot(x, self.w.T) + self.b\n",
        "  \n",
        "  def sigmoid(self, x):\n",
        "    return 1.0/(1.0 + np.exp(-x))\n",
        "  \n",
        "  def grad_w_mse(self, x, y):\n",
        "    y_pred = self.sigmoid(self.perceptron(x))\n",
        "    return (y_pred - y) * y_pred * (1 - y_pred) * x\n",
        "  \n",
        "  def grad_b_mse(self, x, y):\n",
        "    y_pred = self.sigmoid(self.perceptron(x))\n",
        "    return (y_pred - y) * y_pred * (1 - y_pred)\n",
        "  \n",
        "  def grad_w_ce(self, x, y):\n",
        "    y_pred = self.sigmoid(self.perceptron(x))\n",
        "    if y == 0:\n",
        "      return y_pred * x\n",
        "    elif y == 1:\n",
        "      return -1 * (1 - y_pred) * x\n",
        "    else:\n",
        "      raise ValueError(\"y should be 0 or 1\")\n",
        "    \n",
        "  def grad_b_ce(self, x, y):\n",
        "    y_pred = self.sigmoid(self.perceptron(x))\n",
        "    if y == 0:\n",
        "      return y_pred \n",
        "    elif y == 1:\n",
        "      return -1 * (1 - y_pred)\n",
        "    else:\n",
        "      raise ValueError(\"y should be 0 or 1\")\n",
        "  \n",
        "  def fit(self, X, Y, epochs=1, learning_rate=1, initialise=True, loss_fn=\"mse\", display_loss=False):\n",
        "    \n",
        "    # initialise w, b\n",
        "    if initialise:\n",
        "      self.w = np.random.randn(1, X.shape[1])\n",
        "      self.b = 0\n",
        "      \n",
        "    if display_loss:\n",
        "      loss = {}\n",
        "    \n",
        "    for i in tqdm_notebook(range(epochs), total=epochs, unit=\"epoch\"):\n",
        "      dw = 0\n",
        "      db = 0\n",
        "      for x, y in zip(X, Y):\n",
        "        if loss_fn == \"mse\":\n",
        "          dw += self.grad_w_mse(x, y)\n",
        "          db += self.grad_b_mse(x, y) \n",
        "        elif loss_fn == \"ce\":\n",
        "          dw += self.grad_w_ce(x, y)\n",
        "          db += self.grad_b_ce(x, y)\n",
        "          \n",
        "      m = X.shape[1]  \n",
        "      self.w -= learning_rate * dw/m\n",
        "      self.b -= learning_rate * db/m\n",
        "      \n",
        "      if display_loss:\n",
        "        Y_pred = self.sigmoid(self.perceptron(X))\n",
        "        if loss_fn == \"mse\":\n",
        "          loss[i] = mean_squared_error(Y, Y_pred)\n",
        "        elif loss_fn == \"ce\":\n",
        "          loss[i] = log_loss(Y, Y_pred)\n",
        "    \n",
        "    if display_loss:\n",
        "      plt.plot(loss.values())\n",
        "      plt.xlabel('Epochs')\n",
        "      if loss_fn == \"mse\":\n",
        "        plt.ylabel('Mean Squared Error')\n",
        "      elif loss_fn == \"ce\":\n",
        "        plt.ylabel('Log Loss')\n",
        "      plt.show()\n",
        "      \n",
        "  def predict(self, X):\n",
        "    Y_pred = []\n",
        "    for x in X:\n",
        "      y_pred = self.sigmoid(self.perceptron(x))\n",
        "      Y_pred.append(y_pred)\n",
        "    return np.array(Y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CuCO-2rqQ_zb",
        "colab": {}
      },
      "source": [
        "my_cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"red\",\"yellow\",\"green\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O3JppMc9IIpU",
        "colab": {}
      },
      "source": [
        "np.random.seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1Yum3QoCRDku"
      },
      "source": [
        "## Generate data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0Shf39PcRCub",
        "colab": {}
      },
      "source": [
        "data, labels = make_blobs(n_samples=1000, centers=4, n_features=2, random_state=0)\n",
        "print(data.shape, labels.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TTbXyK2kReWT",
        "colab": {}
      },
      "source": [
        "plt.scatter(data[:,0], data[:,1], c=labels, cmap=my_cmap)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NegH_BURRwep",
        "colab": {}
      },
      "source": [
        "labels_orig = labels\n",
        "labels = np.mod(labels_orig, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ep7RO9G6SaKj",
        "colab": {}
      },
      "source": [
        "plt.scatter(data[:,0], data[:,1], c=labels, cmap=my_cmap)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "USn-jj4B0JzB",
        "colab": {}
      },
      "source": [
        "X_train, X_val, Y_train, Y_val = train_test_split(data, labels, stratify=labels, random_state=0)\n",
        "print(X_train.shape, X_val.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1ZOXItAL1T5u"
      },
      "source": [
        "## SN classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1q3McRCR1HhQ",
        "colab": {}
      },
      "source": [
        "sn = SigmoidNeuron()\n",
        "sn.fit(X_train, Y_train, epochs=1000, learning_rate=0.5, display_loss=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lKik8Glh1lX3",
        "colab": {}
      },
      "source": [
        "Y_pred_train = sn.predict(X_train)\n",
        "Y_pred_binarised_train = (Y_pred_train >= 0.5).astype(\"int\").ravel()\n",
        "Y_pred_val = sn.predict(X_val)\n",
        "Y_pred_binarised_val = (Y_pred_val >= 0.5).astype(\"int\").ravel()\n",
        "accuracy_train = accuracy_score(Y_pred_binarised_train, Y_train)\n",
        "accuracy_val = accuracy_score(Y_pred_binarised_val, Y_val)\n",
        "\n",
        "print(\"Training accuracy\", round(accuracy_train, 2))\n",
        "print(\"Validation accuracy\", round(accuracy_val, 2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7CA0lCfc2msD",
        "colab": {}
      },
      "source": [
        "plt.scatter(X_train[:,0], X_train[:,1], c=Y_pred_binarised_train, cmap=my_cmap, s=15*(np.abs(Y_pred_binarised_train-Y_train)+.2))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22tBRZg7rNpj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install ipdb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kUV0BZQBi_hV",
        "colab": {}
      },
      "source": [
        "ffn = FirstFFNetwork()\n",
        "ffn.fit(X_train, Y_train, epochs=2000, learning_rate=.01, display_loss=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Xyl4KYa0AQSV"
      },
      "source": [
        "## Our First FF Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "imu7qdHmASL9",
        "colab": {}
      },
      "source": [
        "import ipdb;\n",
        "class FirstFFNetwork:\n",
        "  \n",
        "  def __init__(self):\n",
        "    self.w1 = np.ones((2,1))\n",
        "    self.w2 = np.ones((2,1))\n",
        "    self.w3 = np.ones((2,1))\n",
        "    self.w4 = np.ones((2,1))\n",
        "    self.w5 = np.ones((2,1))\n",
        "    self.w6 = np.ones((2,1))\n",
        "    self.b1 = 0\n",
        "    self.b2 = 0\n",
        "    self.b3 = 0\n",
        "\n",
        "  def grad_sigmoid(self, X):\n",
        "    return X*(1-X) \n",
        "  \n",
        "  def sigmoid(self, x):\n",
        "    return 1.0/(1.0 + np.(self.h3-y)* self.grad_sigmoid(self.h3)* self.w3exp(-x))\n",
        "  \n",
        "  def forward_pass(self, x):\n",
        "\n",
        "    self.a1 = np.matmul(x,self.w1) + self.b1 #(n,2)*(2,1)\n",
        "    self.h1 = self.sigmoid(self.a1)    \n",
        "    print(self.h1.shape)\n",
        "    self.a2 = np.matmul(x,self.w2) + self.b2\n",
        "    self.h2 = self.sigmoid(self.a2)\n",
        "    print(self.h2.shape)\n",
        "    self.h=np.hstack((self.h1,self.h2))   #n,2\n",
        "    print(self.h.shape)\n",
        "    self.a3 = np.matmul(self.h,self.w3) + self.b3 #(n,2)*(2,1)\n",
        "    self.h3 = self.sigmoid(self.a3)\n",
        "    print(self.h3.shape) #(n,1)\n",
        "    return self.h3\n",
        "    \n",
        "    \"\"\"\n",
        "    self.x1, self.x2 = x\n",
        "    self.a1 = self.w1*self.x1 + self.w2*self.x2 + self.b1  <=> W1=[w1,w2] W2= [w3,w4] W3=[w5,w6]T\n",
        "    self.h1 = self.sigmoid(self.a1)\n",
        "    self.a2 = self.w3*self.x1 + self.w4*self.x2 + self.b2\n",
        "    self.h2 = self.sigmoid(self.a2)\n",
        "    self.a3 = self.w5*self.h1 + self.w6*self.h2 + self.b3 \n",
        "    self.h3 = self.sigmoid(self.a3)\n",
        " \n",
        "    \"\"\"\n",
        "  def grad_sigmoid(self, x):\n",
        "    return x*(1-x) \n",
        "\n",
        "  def grad(self, x, y):\n",
        "    self.forward_pass(x)\n",
        "\n",
        "    \n",
        "    #self.dw5 = (self.h3-y) * self.h3*(1-self.h3) * self.h1\n",
        "    #self.dw6 = (self.h3-y) * self.h3*(1-self.h3) * self.h2\n",
        "   \n",
        "    y=y.reshape(-1,1)\n",
        "    self.dW3=(self.h3-y) * self.grad_sigmoid(self.h3) * self.h #n,1\n",
        "    self.dB3 = (self.h3-y) * self.h3*(1-self.h3) #(N,1)\n",
        "    ipdb.set_trace()\n",
        "    #self.dw1 = (self.h3-y) * self.h3*(1-self.h3) * self.w5 * self.h1*(1-self.h1) * self.x1\n",
        "    #self.dw2 = (self.h3-y) * self.h3*(1-self.h3) * self.w5 * self.h1*(1-self.h1) * self.x2\n",
        "    #self.db1 = (self.h3-y) * self.h3*(1-self.h3) * self.w5 * self.h1*(1-self.h1)\n",
        "    self.dW =  (self.h3-y)* self.grad_sigmoid(self.h3)* self.w3.T*self.grad_sigmoid(self.h)*x #(2,2)\n",
        "    self.dB =  (self.h3-y)* self.grad_sigmoid(self.h3)* self.w3.T*self.grad_sigmoid(self.h)  #(N,2)\n",
        "    print(self.dW.shape)\n",
        "    print(self.dB.shape)\n",
        "  \n",
        "    #self.dw3 = (self.h3-y) * self.h3*(1-self.h3) * self.w6 * self.h2*(1-self.h2) * self.x1\n",
        "    #self.dw4 = (self.h3-y) * self.h3*(1-self.h3) * self.w6 * self.h2*(1-self.h2) * self.x2\n",
        "    #self.db2 = (self.h3-y) * self.h3*(1-self.h3) * self.w6 * self.h2*(1-self.h2)\n",
        "    \"\"\"\n",
        "      self.forward_pass(X)\n",
        "        m = X.shape[0]\n",
        "        \n",
        "        self.dA2 = self.H2 - Y # (N, 4) - (N, 4) -> (N, 4)\n",
        "        \n",
        "        self.dW2 = np.matmul(self.H1.T, self.dA2) # (2, N) * (N, 4) -> (2, 4)\n",
        "        self.dB2 = np.sum(self.dA2, axis=0).reshape(1, -1) # (N, 4) -> (1, 4)\n",
        "        self.dH1 = np.matmul(self.dA2, self.W2.T) # (N, 4) * (4, 2) -> (N, 2)\n",
        "        self.dA1 = np.multiply(self.dH1, self.grad_sigmoid(self.H1)) # (N, 2) .* (N, 2) -> (N, 2)\n",
        "        \n",
        "        self.dW1 = np.matmul(X.T, self.dA1) # (2, N) * (N, 2) -> (2, 2)\n",
        "        self.dB1 = np.sum(self.dA1, axis=0).reshape(1, -1) # (N, 2) -> (1, 2)\n",
        "\n",
        "    \"\"\"\n",
        "  def fitFF(self, X, Y, epochs=1, learning_rate=1, initialise=True, display_loss=False):\n",
        "    print(X.shape)\n",
        "    # initialise w, b\n",
        "    if initialise:\n",
        "      self.w1 = np.ones((2,1))\n",
        "      self.w2 = np.ones((2,1))\n",
        "      self.w3 = np.ones((2,1))\n",
        "      self.b1 = 0\n",
        "      self.b2 = 0\n",
        "      self.b3 = 0\n",
        "     \n",
        "    if display_loss:\n",
        "      loss = {}\n",
        "    \n",
        "    for i in tqdm_notebook(range(epochs), total=epochs, unit=\"epoch\"):\n",
        "      y_pred = self.forward_pass(X)\n",
        "\n",
        "    return y_pred.shape\n",
        " \n",
        "  def fit(self, X, Y, epochs=1, learning_rate=1, initialise=True, display_loss=False):\n",
        "  \n",
        "    # initialise w, b\n",
        "    if initialise:\n",
        "      self.w1 = np.ones((2,1))\n",
        "      self.w2 = np.ones((2,1))\n",
        "      self.w3 = np.ones((2,1))\n",
        "      self.b1 = 0\n",
        "      self.b2 = 0\n",
        "      self.b3 = 0\n",
        "     \n",
        "    if display_loss:\n",
        "      loss = {}\n",
        "    \n",
        "    for i in tqdm_notebook(range(epochs), total=epochs, unit=\"epoch\"):\n",
        "      \n",
        "      \"\"\"\n",
        "          self.a1 = np.matmul(x,self.w1) + self.b1 #(n,2)*(2,1)\n",
        "         self.h1 = self.sigmoid(self.a1)    \n",
        "          self.a2 = np.matmul(x,self.w2) + self.b2\n",
        "          self.h2 = self.sigmoid(self.a2)\n",
        "          self.h=np.array([self.h1,self.h2])\n",
        "          self.a3 = np.matmul(self.h,self.w3.T) + self.b3 #(n,1)* (1,2) \n",
        "          self.h3 = self.sigmoid(self.a3)\n",
        "\n",
        "             self.dW3=(self.h3-y) * self.h3*(1-self.h3) * self.h\n",
        "        self.dB3 = (self.h3-y) * self.h3*(1-self.h3) #(N,1)\n",
        "      \n",
        "      self.dW =  (self.h3-y)* grad_sigmoid(self.h3)* w3.T*grad_sigmoid(self.h)*X #(2,2)\n",
        "       self.dB =  (self.h3-y)* grad_sigmoid(self.h3)* w3.T*grad_sigmoid(self.h)  #(N,2)\n",
        "   W=[h1,h]\n",
        "      \n",
        "      \"\"\"\n",
        "      \n",
        "      self.grad(X,Y)\n",
        "      ipdb.set_trace()\n",
        "      dw1 += self.dW\n",
        "      dw2 += self.dW\n",
        "      dw3 += self.dW3.T\n",
        "      db1 += self.dB[0]\n",
        "      db2 += self.dB[1]\n",
        "      db3 += self.dB3\n",
        "        \n",
        "      m = X.shape[1]\n",
        "      self.w1 -= learning_rate * dw1 / m\n",
        "      self.w2 -= learning_rate * dw2 / m\n",
        "      self.w3 -= learning_rate * dw3 / m\n",
        "      self.w4 -= learning_rate * dw4 / m\n",
        "      self.w5 -= learning_rate * dw5 / m\n",
        "      self.w6 -= learning_rate * dw6 / m\n",
        "      self.b1 -= learning_rate * db1 / m\n",
        "      self.b2 -= learning_rate * db2 / m\n",
        "      self.b3 -= learning_rate * db3 / m\n",
        "      \n",
        "    if display_loss:\n",
        "      Y_pred = self.predict(X)\n",
        "      loss[i] = mean_squared_error(Y_pred, Y)\n",
        "\n",
        "    if display_loss:\n",
        "      plt.plot(loss.values())\n",
        "      plt.xlabel('Epochs')\n",
        "      plt.ylabel('Mean Squared Error')\n",
        "      plt.show()\n",
        "      \n",
        "  def predict(self, X):\n",
        "    Y_pred = []\n",
        "    for x in X:\n",
        "      y_pred = self.forward_pass(x)\n",
        "      Y_pred.append(y_pred)\n",
        "    return np.array(Y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_0e5zdMOIgv_"
      },
      "source": [
        "## FFNetwork Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u-eV9Uj4HSt7",
        "colab": {}
      },
      "source": [
        "ffn = FirstFFNetwork()\n",
        "ffn.fitFF(X_train, Y_train, epochs=2000, learning_rate=.01, display_loss=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vrsFuFprIrn6",
        "colab": {}
      },
      "source": [
        "Y_pred_train = ffn.predict(X_train)\n",
        "Y_pred_binarised_train = (Y_pred_train >= 0.5).astype(\"int\").ravel()\n",
        "Y_pred_val = ffn.predict(X_val)\n",
        "Y_pred_binarised_val = (Y_pred_val >= 0.5).astype(\"int\").ravel()\n",
        "accuracy_train = accuracy_score(Y_pred_binarised_train, Y_train)\n",
        "accuracy_val = accuracy_score(Y_pred_binarised_val, Y_val)\n",
        "\n",
        "print(\"Training accuracy\", round(accuracy_train, 2))\n",
        "print(\"Validation accuracy\", round(accuracy_val, 2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6vuROfG2Jc54",
        "colab": {}
      },
      "source": [
        "plt.scatter(X_train[:,0], X_train[:,1], c=Y_pred_binarised_train, cmap=my_cmap, s=15*(np.abs(Y_pred_binarised_train-Y_train)+.2))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GsCZesAUB8L0"
      },
      "source": [
        "## Feed Forward Network - Generic Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MMlGP34rJgiS",
        "colab": {}
      },
      "source": [
        "class FFSNNetwork:\n",
        "  \n",
        "  def __init__(self, n_inputs, hidden_sizes=[2]):\n",
        "    self.nx = n_inputs\n",
        "    self.ny = 1\n",
        "    self.nh = len(hidden_sizes)\n",
        "    self.sizes = [self.nx] + hidden_sizes + [self.ny]\n",
        "    \n",
        "    self.W = {}\n",
        "    self.B = {}\n",
        "    for i in range(self.nh+1):\n",
        "      self.W[i+1] = np.random.randn(self.sizes[i], self.sizes[i+1])\n",
        "      self.B[i+1] = np.zeros((1, self.sizes[i+1]))\n",
        "  \n",
        "  def sigmoid(self, x):\n",
        "    return 1.0/(1.0 + np.exp(-x))\n",
        "  \n",
        "  def forward_pass(self, x):\n",
        "    self.A = {}\n",
        "    self.H = {}\n",
        "    self.H[0] = x.reshape(1, -1)\n",
        "    for i in range(self.nh+1):\n",
        "      self.A[i+1] = np.matmul(self.H[i], self.W[i+1]) + self.B[i+1]\n",
        "      self.H[i+1] = self.sigmoid(self.A[i+1])\n",
        "    return self.H[self.nh+1]\n",
        "  \n",
        "  def grad_sigmoid(self, x):\n",
        "    return x*(1-x) \n",
        "    \n",
        "  def grad(self, x, y):\n",
        "    self.forward_pass(x)\n",
        "    self.dW = {}\n",
        "    self.dB = {}\n",
        "    self.dH = {}\n",
        "    self.dA = {}\n",
        "    L = self.nh + 1\n",
        "    self.dA[L] = (self.H[L] - y)\n",
        "    for k in range(L, 0, -1):\n",
        "      self.dW[k] = np.matmul(self.H[k-1].T, self.dA[k])\n",
        "      self.dB[k] = self.dA[k]\n",
        "      self.dH[k-1] = np.matmul(self.dA[k], self.W[k].T)\n",
        "      self.dA[k-1] = np.multiply(self.dH[k-1], self.grad_sigmoid(self.H[k-1]))\n",
        "    \n",
        "  def fit(self, X, Y, epochs=1, learning_rate=1, initialise=True, display_loss=False):\n",
        "    \n",
        "    # initialise w, b\n",
        "    if initialise:\n",
        "      for i in range(self.nh+1):\n",
        "        self.W[i+1] = np.random.randn(self.sizes[i], self.sizes[i+1])\n",
        "        self.B[i+1] = np.zeros((1, self.sizes[i+1]))\n",
        "      \n",
        "    if display_loss:\n",
        "      loss = {}\n",
        "    \n",
        "    for e in tqdm_notebook(range(epochs), total=epochs, unit=\"epoch\"):\n",
        "      dW = {}\n",
        "      dB = {}\n",
        "      for i in range(self.nh+1):\n",
        "        dW[i+1] = np.zeros((self.sizes[i], self.sizes[i+1]))\n",
        "        dB[i+1] = np.zeros((1, self.sizes[i+1]))\n",
        "      for x, y in zip(X, Y):\n",
        "        self.grad(x, y)\n",
        "        for i in range(self.nh+1):\n",
        "          dW[i+1] += self.dW[i+1]\n",
        "          dB[i+1] += self.dB[i+1]\n",
        "        \n",
        "      m = X.shape[1]\n",
        "      for i in range(self.nh+1):\n",
        "        self.W[i+1] -= learning_rate * dW[i+1] / m\n",
        "        self.B[i+1] -= learning_rate * dB[i+1] / m\n",
        "      \n",
        "      if display_loss:\n",
        "        Y_pred = self.predict(X)\n",
        "        loss[e] = mean_squared_error(Y_pred, Y)\n",
        "    \n",
        "    if display_loss:\n",
        "      plt.plot(loss.values())\n",
        "      plt.xlabel('Epochs')\n",
        "      plt.ylabel('Mean Squared Error')\n",
        "      plt.show()\n",
        "      \n",
        "  def predict(self, X):\n",
        "    Y_pred = []\n",
        "    for x in X:\n",
        "      y_pred = self.forward_pass(x)\n",
        "      Y_pred.append(y_pred)\n",
        "    return np.array(Y_pred).squeeze()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sE0vGDb6t2iZ",
        "colab": {}
      },
      "source": [
        "ffsnn = FFSNNetwork(2, [2, 3])\n",
        "ffsnn.fit(X_train, Y_train, epochs=1000, learning_rate=.001, display_loss=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Tnq4ePo6uHtv",
        "colab": {}
      },
      "source": [
        "Y_pred_train = ffsnn.predict(X_train)\n",
        "Y_pred_binarised_train = (Y_pred_train >= 0.5).astype(\"int\").ravel()\n",
        "Y_pred_val = ffsnn.predict(X_val)\n",
        "Y_pred_binarised_val = (Y_pred_val >= 0.5).astype(\"int\").ravel()\n",
        "accuracy_train = accuracy_score(Y_pred_binarised_train, Y_train)\n",
        "accuracy_val = accuracy_score(Y_pred_binarised_val, Y_val)\n",
        "\n",
        "print(\"Training accuracy\", round(accuracy_train, 2))\n",
        "print(\"Validation accuracy\", round(accuracy_val, 2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7q8AaXxGvDJk",
        "colab": {}
      },
      "source": [
        "plt.scatter(X_train[:,0], X_train[:,1], c=Y_pred_binarised_train, cmap=my_cmap, s=15*(np.abs(Y_pred_binarised_train-Y_train)+.2))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rLpsoFqkPWCA"
      },
      "source": [
        "## Multi class classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SpWP4Lh-vG3Y",
        "colab": {}
      },
      "source": [
        "class FFSN_MultiClass:\n",
        "  \n",
        "  def __init__(self, n_inputs, n_outputs, hidden_sizes=[3]):\n",
        "    self.nx = n_inputs\n",
        "    self.ny = n_outputs\n",
        "    self.nh = len(hidden_sizes)\n",
        "    self.sizes = [self.nx] + hidden_sizes + [self.ny] \n",
        "\n",
        "    self.W = {}\n",
        "    self.B = {}\n",
        "    for i in range(self.nh+1):\n",
        "      self.W[i+1] = np.random.randn(self.sizes[i], self.sizes[i+1])\n",
        "      self.B[i+1] = np.zeros((1, self.sizes[i+1]))\n",
        "      \n",
        "  def sigmoid(self, x):\n",
        "    return 1.0/(1.0 + np.exp(-x))\n",
        "  \n",
        "  def softmax(self, x):\n",
        "    exps = np.exp(x)\n",
        "    return exps / np.sum(exps)\n",
        "\n",
        "  def forward_pass(self, x):\n",
        "    self.A = {}\n",
        "    self.H = {}\n",
        "    self.H[0] = x.reshape(1, -1)\n",
        "    for i in range(self.nh):\n",
        "      self.A[i+1] = np.matmul(self.H[i], self.W[i+1]) + self.B[i+1]\n",
        "      self.H[i+1] = self.sigmoid(self.A[i+1])\n",
        "    self.A[self.nh+1] = np.matmul(self.H[self.nh], self.W[self.nh+1]) + self.B[self.nh+1]\n",
        "    self.H[self.nh+1] = self.softmax(self.A[self.nh+1])\n",
        "    return self.H[self.nh+1]\n",
        "  \n",
        "  def predict(self, X):\n",
        "    Y_pred = []\n",
        "    for x in X:\n",
        "      y_pred = self.forward_pass(x)\n",
        "      Y_pred.append(y_pred)\n",
        "    return np.array(Y_pred).squeeze()\n",
        " \n",
        "  def grad_sigmoid(self, x):\n",
        "    return x*(1-x) \n",
        "  \n",
        "  def cross_entropy(self,label,pred):\n",
        "    yl=np.multiply(pred,label)\n",
        "    yl=yl[yl!=0]\n",
        "    yl=-np.log(yl)\n",
        "    yl=np.mean(yl)\n",
        "    return yl\n",
        " \n",
        "  def grad(self, x, y):\n",
        "    self.forward_pass(x)\n",
        "    self.dW = {}\n",
        "    self.dB = {}\n",
        "    self.dH = {}\n",
        "    self.dA = {}\n",
        "    L = self.nh + 1\n",
        "    self.dA[L] = (self.H[L] - y)\n",
        "    for k in range(L, 0, -1):\n",
        "      self.dW[k] = np.matmul(self.H[k-1].T, self.dA[k])\n",
        "      self.dB[k] = self.dA[k]\n",
        "      self.dH[k-1] = np.matmul(self.dA[k], self.W[k].T)\n",
        "      self.dA[k-1] = np.multiply(self.dH[k-1], self.grad_sigmoid(self.H[k-1])) \n",
        "    \n",
        "  def fit(self, X, Y, epochs=100, initialize='True', learning_rate=0.01, display_loss=False):\n",
        "      \n",
        "    if display_loss:\n",
        "      loss = {}\n",
        "      \n",
        "    if initialize:\n",
        "      for i in range(self.nh+1):\n",
        "        self.W[i+1] = np.random.randn(self.sizes[i], self.sizes[i+1])\n",
        "        self.B[i+1] = np.zeros((1, self.sizes[i+1]))\n",
        "        \n",
        "    for epoch in tqdm_notebook(range(epochs), total=epochs, unit=\"epoch\"):\n",
        "      dW = {}\n",
        "      dB = {}\n",
        "      for i in range(self.nh+1):\n",
        "        dW[i+1] = np.zeros((self.sizes[i], self.sizes[i+1]))\n",
        "        dB[i+1] = np.zeros((1, self.sizes[i+1]))\n",
        "      for x, y in zip(X, Y):\n",
        "        self.grad(x, y)\n",
        "        for i in range(self.nh+1):\n",
        "          dW[i+1] += self.dW[i+1]\n",
        "          dB[i+1] += self.dB[i+1]\n",
        "                  \n",
        "      m = X.shape[1]\n",
        "      for i in range(self.nh+1):\n",
        "        self.W[i+1] -= learning_rate * (dW[i+1]/m)\n",
        "        self.B[i+1] -= learning_rate * (dB[i+1]/m)\n",
        "        \n",
        "      if display_loss:\n",
        "        Y_pred = self.predict(X) \n",
        "        loss[epoch] = self.cross_entropy(Y, Y_pred)\n",
        "    \n",
        "    if display_loss:\n",
        "      plt.plot(loss.values())\n",
        "      plt.xlabel('Epochs')\n",
        "      plt.ylabel('CE')\n",
        "      plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Oc-rmmXDusH2",
        "colab": {}
      },
      "source": [
        "X_train, X_val, Y_train, Y_val = train_test_split(data, labels_orig, stratify=labels_orig, random_state=0)\n",
        "print(X_train.shape, X_val.shape, labels_orig.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r8ktticiusH6",
        "colab": {}
      },
      "source": [
        "enc = OneHotEncoder()\n",
        "# 0 -> (1, 0, 0, 0), 1 -> (0, 1, 0, 0), 2 -> (0, 0, 1, 0), 3 -> (0, 0, 0, 1)\n",
        "y_OH_train = enc.fit_transform(np.expand_dims(Y_train,1)).toarray()\n",
        "y_OH_val = enc.fit_transform(np.expand_dims(Y_val,1)).toarray()\n",
        "print(y_OH_train.shape, y_OH_val.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hVl50rhuusH8",
        "colab": {}
      },
      "source": [
        "ffsn_multi = FFSN_MultiClass(2,4,[2,3])\n",
        "ffsn_multi.fit(X_train,y_OH_train,epochs=2000,learning_rate=.005,display_loss=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RN-RQM6TusH_",
        "colab": {}
      },
      "source": [
        "Y_pred_train = ffsn_multi.predict(X_train)\n",
        "Y_pred_train = np.argmax(Y_pred_train,1)\n",
        "\n",
        "Y_pred_val = ffsn_multi.predict(X_val)\n",
        "Y_pred_val = np.argmax(Y_pred_val,1)\n",
        "\n",
        "accuracy_train = accuracy_score(Y_pred_train, Y_train)\n",
        "accuracy_val = accuracy_score(Y_pred_val, Y_val)\n",
        "\n",
        "print(\"Training accuracy\", round(accuracy_train, 2))\n",
        "print(\"Validation accuracy\", round(accuracy_val, 2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ijatqLy2usIG",
        "colab": {}
      },
      "source": [
        "plt.scatter(X_train[:,0], X_train[:,1], c=Y_pred_train, cmap=my_cmap, s=15*(np.abs(np.sign(Y_pred_train-Y_train))+.1))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y3UpXEpCZg5S"
      },
      "source": [
        "## Exercises"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yF0aR4plZl8M",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import make_moons, make_circles"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7Gm13Dw7usIK",
        "colab": {}
      },
      "source": [
        "data, labels = make_moons(n_samples=1000, random_state=0, noise=0.15)\n",
        "print(data.shape, labels.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KB-8kWhLZw7A",
        "colab": {}
      },
      "source": [
        "plt.scatter(data[:,0], data[:,1], c=labels, cmap=my_cmap)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DfRGn_ZUZxp_",
        "colab": {}
      },
      "source": [
        "data, labels = make_circles(n_samples=1000, random_state=0, noise=0.2, factor=0.3)\n",
        "print(data.shape, labels.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VdF8hr39aO4n",
        "colab": {}
      },
      "source": [
        "plt.scatter(data[:,0], data[:,1], c=labels, cmap=my_cmap)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T4Ue0dRtbEK8",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}